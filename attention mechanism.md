# introduce [参考](https://machinelearningmastery.com/the-attention-mechanism-from-scratch/)
* 提出attention mechanism的文章[链接](https://arxiv.org/abs/1409.0473)
* The attention mechanism was introduced to improve the performance of the encoder-decoder model for machine translation. The idea behind the attention mechanism was to permit the decoder to utilize the most relevant parts of the input sequence in a flexible manner, by a weighted combination of all of the encoded input vectors, with the most relevant vectors being attributed the highest weights. 

